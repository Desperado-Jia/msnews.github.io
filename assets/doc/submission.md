# Submission Guidelines

In this tutorial, we will cover the process of participating in the competition, downloading our `MIND` dataset, submitting your prediction data and receiving the official evaluation results on `MIND` dataset.

## Participate In Competition
The MIND News Recommendation Competition is hold on Codalab platform. 
Before you begins, please create a [Codalab account](https://worksheets.codalab.org/) and finish the [Codalab tutorial](https://codalab-worksheets.readthedocs.io/en/latest/).
Please read [Microsoft Research License Terms](https://github.com/msnews/MIND/blob/master/MSR%20License_Data.pdf) before you participate in the competition.
Enter the [home page](https://competitions.codalab.org/competitions/24122?secret_key=e075b839-d0cb-4c7b-b755-b34c5a666cba) of MIND competition and agree to participate.

## Download Dataset
**MIcrosoft News Dataset** (MIND) is a large-scale dataset for news recommendation research, which contains 1,000,000 users, 161,013 English news articles and 15,777,377 impression logs.

You can download the [MIND dataset](https://msnews.github.io/#getting-start) after you agree to [Microsoft Research License Terms](https://github.com/msnews/MIND/blob/master/MSR%20License_Data.pdf).
For more details about the data formats, please refer to [the document](https://github.com/msnews/msnews.github.io/blob/master/assets/doc/introduction.md).


## Submission Formats
System submissions to CodaLab should be zip-compressed, containing a prediction file named `answer.json`. The evaluation script will evaluate your prediction against the gold labels. The script, as well as a [sample prediction file](https://github.com/msnews/MIND/blob/master/sample_answer.zip) can be found on github. Following are several key points:

* A valid zip submission should contain nothing but a json file named answer.json (*)
* Do not place the submission json file within folders before it is compressed
* The format of each line in the file is a json object like: `{"uid": xxx, "impression": { "nid1": your prediction,"nid2": your prediction }, "time": xxx}`
* The row orders of the results should be consistent with those in the original files.
* The predicted click scores are float numbers, which are no greater than 1 or less than 0.
* The type of user ids and news ids are string (e.g., "123" rather than 123).
* (*) For Mac users: make sure that it contains no __macosx file.

 

## Development Phase
During the development phase, teams can upload their predictions on the development set. This submission is NOT obligatory, but we highly encourage you to submit in case that you have troubles in obtaining the normal evaluation results, and can also be useful practice for those participants new to CodaLab. The [sample submission file](https://github.com/msnews/MIND/blob/master/sample_answer.zip) generated by our baseline system can be downloaded from Github.

Submission guide:

* Participant in [our competition](https://competitions.codalab.org/competitions/24122?secret_key=e075b839-d0cb-4c7b-b755-b34c5a666cba)
* Navigate to 'Participate'
* Write a description of your submission (optional) 
* Click the button 'Submit / View Results'
* Upload your zipped submission
* Wait until the evaluation status turns to 'Finished' or 'Failed'

If the submission status is 'Failed', you can click 'View scoring output log' and 'View scoring error log' to see the debug logs. When the evaluation is finished, you can click 'Download output from scoring step' to see your evaluation results. You can decide whether to show your scores on the leaderboard.

*Important*: You can only upload at most 3 submissions each day in order not to overwhelm the system.

## Test Phase
During the test phase, teams can upload their submissions on the test data by following the same process as in the development phase. Note that the leaderboard will **NOT** be visible during the test phase, and you cannot see the evaluation results on the test set. The results will be posted a few weeks after the end of the test phase since we need to check the validity of each submission and fix the broken submissions.

*Important* : You can only upload at most 3 submissions each day, and the last submission during the test phase will be regarded as the official submission of a team.